{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_3_Linear_Neural_Network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNR5+8Zkg3Bkvpe7KG3k9a4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huunghia160799/Dive-into-Deep-Learning/blob/master/Chapter_3_Linear_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5CG6EeAoTJA",
        "colab_type": "text"
      },
      "source": [
        "# 3.1 Linear Regression\n",
        "\n",
        "## Exercises\n",
        "\n",
        "2. \n",
        "- The optimization problem: $\\operatorname*{argmin}_{\\mathbf{w}} L = \\operatorname*{argmin}_{\\mathbf{w}} \\frac{1}{2} (\\mathbf{X}\\mathbf{w} - \\mathbf y)^2$.\n",
        "\n",
        "- The gradient of the loss w.r.t $\\mathbf{w}$:\n",
        "\n",
        "    $\\frac{\\partial \\mathbf{L}}{\\partial \\mathbf{w}} = \\mathbf{(Xw - y)X}$\n",
        "\n",
        "- To minimize the lost, we consider:\n",
        "\n",
        "    $\\frac{\\partial \\mathbf{L}}{\\partial \\mathbf{w}} = 0$\n",
        "    \n",
        "    $\\iff \\mathbf{(Xw - y)} = 0$\n",
        "\n",
        "    $\\iff \\mathbf{Xw = y}$\n",
        "\n",
        "    $\\iff \\mathbf{X^\\top X w = X^\\top y}$\n",
        "\n",
        "    $\\iff \\mathbf{w = (X^\\top X)^{-1} X^\\top y}$\n",
        "\n",
        "- This method is better than stochastic gradient descent in the linear regression case because it has smaller computational complexity. Howeverr, for loss functions that are more complicated, it is tedious and error-prone to extract a closed-form solution by hand.\n",
        "\n",
        "3. \n"
      ]
    }
  ]
}